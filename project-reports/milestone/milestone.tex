%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
%\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
%\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\usepackage{sectsty} % Allows customizing section commands
%\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

%\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
\textsc{Stanford CS 229 Fall 2017} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\Large Final Project Milestone: \\
\Large Real Time Tennis Match Prediction Using Machine Learning\\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Yang "Eddie" Chen, Yi Zhong, Yubo Tian} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%	Section 1 Motivation
%----------------------------------------------------------------------------------------

\section{Motivation}
Tennis matches are fun to watch because they are full of surprises. In the 2017 Stuttgart Open, Roger Federer, then an 18-time grand slam champion, lost to the world No. 302 player Tommy Haas. Federer lost the opening match at a grass-court tournament, a phenomenon that hadn't happened since 2002. How can we predict a rare loss like this? Based on past performance alone, any model would have predicted a Federer win in pre-game bets. This motivates us to apply machine learning to predict tennis matches in real time; in particular, we want to explore how well we can combine both historical performance data and real-time, just-happened set-by-set outcome, to achieve a better prediction. Anecdotally, most of us probably have been consumers of ESPN’s in-game predictions when watching an NFL game on ESPN’s website, with a win chance chart displaying the real-time probability that ESPN thinks each team has. We hope, with a similar hybrid model that combines historical and real-time information, both tennis players and sports bettors can benefit from better predictions and new insights. 

Tennis is an ideal candidate for a hierarchical model as a match consists of a sequence of sets, which in turn consist of a sequence of games, which in turn consist of a sequence of points. Extensive researches have been done on tennis pre-game predictions. ATP provides prediction before game based on past performance (including previous encounter, current ranking, etc). Utilizing existing data and building on top of existing research such as Sipko \cite{tennis1}, Clarke and Dyte \cite{Clarke2010} and Knottenbelt \cite{KNOTTENBELT20123820}, this paper seeks to apply classification algorithms from machine learning to model men's professional singles matches innovatively by using both pre-game, historical performance calcualted via a common opponent model \cite{KNOTTENBELT20123820}, and real-time, on-court stats \cite{tennis_charting} \cite{tennis2setbyset}. As pointed out by Sipko \cite{tennis1}, an in-game "approach to tennis match prediction can be more accurate, as it allows the model to capture the change in a player's performance over the course of the match. For example, different players fatigue during a match in different ways." We hope that results from our predictions can be extended to give real-time coaching advice to support game strategy decision.
%----------------------------------------------------------------------------------------
%	Section 2 - Method
%----------------------------------------------------------------------------------------

\section{Method}
\subsection{Feature Extraction}
\subsubsection{Feature Representation}
A supervised machine learning algorithm requires a set of labeled examples for training. In our project, each training example combines both the historical aspect, which is the stats calculated from the past, and the real-time aspect, which is the immediately preceding set information. (Reminder that our project focuses on predicting match outcome form both the historical data and the real-time info). In terms of representation, the training example is made up of:
\begin{enumerate}
\item A vector of input features (X), describing the players and the match
\item A target value (y), indicating the match outcome
\end{enumerate}
In any given singles match, we have two players in one game. We denote them as Player 1 and Player 2, and thus define the target value as 
$y = 1$ if Player 1 wins, 0 otherwise.
\subsubsection{Symmetric Match \& Set Feature Representation}
As suggested by Sipko \cite{tennis1} and Clarke and Dyte \cite{Clarke2010}, when considering the charateristics of \textit{both} players in a given match, we are mainly interested in the \textit{difference} between two players for our variables of interest. Take for example, the rank information between two players for a given match. We construct a single feature called $RANK_DIFF = RANK_1 - RANK_2$, where $RANK_1$ and $RANK_2$ are the ranks of players 1 and 2 respectively at the time of the match. We selected this design (as opposed to the alternative of including both players' info, such as both $RANK_1$ and $RANK_2$), because previous research has shown that the difference variables are predictive enough \cite{tennis1} \cite{omalley}, and this way we cut down the feature size by half as compared to the alternative. Reduced feature column count reduces the \textit{variance} of the model. Moreover, using difference variables allows us to have a symmetric model: it will produce the same results even if we swap Player 1 and Player 2, and define $y = 1$ if Player 2 wins, 0 otherwise. Should we have two different variables such as $RANK_1$ and $RANK_2$ for an asymmetric model, the model might assign different weights to the two variables despite them referring to the same foundamental feature, only differing by the player labelling. Having a \textit{symmetric} model eliminates the bias from that, as we only have one single difference variable for each feature now. 
\subsubsection{Hybridizing Match \& Set Features}
\textbf{TODO}
\subsubsection{Common Opponent Model}
We use a method proposed by Knottenbelt \cite{KNOTTENBELT20123820} to construct difference variables capturing player characteristics and past performance, by using their \textbf{common opponents} so as to achieve a fair comparison. Although this technique was developed for use in a hierarchical Markov model, Spiko \cite{tennis1} has shown that it adapts well in the land of machine learning algorithms and modeling. 

To show how we construct the features, we first look for a set of \textbf{common opponents} between the two players of a given match. Here, \textbf{common opponents} are defined as other players that the two (Player 1 and Player 2) have faced in the past on their own. Once we have all the common opponents, we find both players' performance against the common opponent ($C_i$), and average across all the common opponents. Lastly, we find the difference between the two players' average stats against common opponents as the selected feature. Figure \ref{fig:CO} shows an example of how we could construct the \textbf{ACE} feature (difference in average ace counts) against common opponents. 
\begin{figure}
  \caption{Constructing the ACE feature using common opponents}
  \centering
    \includegraphics[width=0.8\textwidth]{CO}
  \label{fig:CO}
\end{figure}
As shown in Figure \ref{fig:CO}, common opponents are labeled as $C_1, C_2, ...C_n$. For Player $i \in \{1,2\}$, $ACE_i(C_j)$ is his/her average count of aces in all matches against common opponent $C_j$. We then take an average of these values to get $ACE_i$ for Player $i$: $$ACE_i = \frac{\Sigma_{j=0}^n ACE_i(C_j)}{n}$$
Lastly, applying the idea of difference variables, we create the feature ACE by finding the difference in performance on this feature between Player 1 and Player 2: $$ACE = ACE_1 - ACE_2$$. 
We can apply the same technique on other features too. The limitation of this method is apparent: it only works well when players actually have common opponents have played games with them before the queried match date. Hence, we need to think about how to handle edge cases.
\subsubsection{Edge Cases}
We have run into 2 edge cases: (1) when at least one of the players is new; (2) when two players do not have any common opponents. When (1) happens, it is necessarily the case that it suffers from (2) no common opponents as well; but the reverse is not true. \textbf{TODO}: add in what we decided to do
\subsection{Data Preparation}
\subsubsection{Data Source}
We obtain match-level data from Jeff Sackmann's Github repositories \cite{tennis_atp} \cite{tennis_charting}, with the Match Charting Project (MCP) providing set-level stats and results as well \cite{tennis_charting}. MCP is essentially a crowdsourced shot-by-shot professional tennis dataset, and it enables us to have a real-time lens into tennis matches. 
\subsubsection{Data Cleaning \& Transformation}
\textbf{TODO}: Things to talk about:
\begin{itemize}
\item Validations run on the datasets
\item How to detect and remove duplicates
\item Decision on dropping Davis Cup data (because team tourney might have different strategies, hence introducing biases)
\item How to merge two datasets together
\item (TODO for future work) Standardize features? 
\end{itemize}
\subsection{Feature List}
We present the list of extracted features in Table \ref{tab:features}. Note that all these features are difference variables unless otherwise noted. 
\begin{center}
\begin{table}[h]
    \begin{tabular}{  l | p{10cm} }
    \hline
    Feature  & Description \\ \hline
    \textbf{DURATION}  & Match duration in minutes \\ \hline
    \textbf{SAME\_HANDEDNESS}  & Tracking, on average, the frequency of facing opponents who have the same dominant hand \\ \hline
    \textbf{RANK}  & ATP rank \\ \hline
    \textbf{RANK\_PTS}  & ATP rank points \\ \hline
    \textbf{HEIGHT}  & Player height \\ \hline
    \textbf{FSP}  & First serve success percentage \\ \hline
    \textbf{ACE}  & Average number of aces per game \\ \hline
    \textbf{DF}  & Average number of double faults per game \\ \hline
    \textbf{BP\_FACED}  & Average number of break points faced per game \\ \hline
    \textbf{BP\_SAVED}  & Average number of break points saved per game \\ \hline
    \textbf{BPP}  & Break point saving percentage \\ \hline
    \textbf{SVGM}  & Average number of serve games \\ \hline
    \textbf{W1SP}  & Winning on first serve percentage \\ \hline
    \textbf{W2SP}  & Winning on second serve percentage \\ \hline
    \textbf{SVPT}  & Average number of serve points per game \\ \hline
    \end{tabular}
    \caption{Summary of extracted features}
    \label{tab:features}
    \end{table}
\end{center}
%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
%	Section Preliminary Experiments
%----------------------------------------------------------------------------------------

\section{Preliminary Experiments}
\subsection{Logistic Regression Model}
\subsection{Naive Bayes Classifier}

%----------------------------------------------------------------------------------------
%	Section Next Steps
%----------------------------------------------------------------------------------------

\section{Next Steps}

%----------------------------------------------------------------------------------------
%	Section Contributions
%----------------------------------------------------------------------------------------

\section{Contributions}
\subsection{Yi Zhong}
\subsection{Yubo Tian}
\subsection{Yang "Eddie" Chen}
\begin{itemize}
\item Researched and reviewed relevant literature for applicable ideas, such as Clarke and Dyte \cite{Clarke2010} and O'Malley \cite{omalley} for difference variable, and Knottenbelt \cite{KNOTTENBELT20123820} for the common opponent model
\item Implemented the Common Opponent Model to look up players stats from common opponents
\item Generated ATP Match results for labels
\item Typsetted (\LaTeX) the project milestone report
\end{itemize}
%----------------------------------------------------------------------------------------
%	Conclusion
%----------------------------------------------------------------------------------------

\section{Conclusion}

\appendix
\section{Appendix: Project Roadmap}
\begin{itemize}
\item \textbf{11/13 - 11/19}: Data cleaning
\item \textbf{11/20 - 11/26}: Preliminary experiements, building out more sophisticated ideas into models such as surface weighting, time decaying, fatigue, and injury
\item \textbf{11/27 - 12/03}: Continue fine-tuning models
\item \textbf{12/04 - 12/10}: Poster making
\item \textbf{12/11 - 12/15}: Poster presentation; final project write-up
\end{itemize}

\bibliographystyle{plain}
\bibliography{ref} 
\end{document}