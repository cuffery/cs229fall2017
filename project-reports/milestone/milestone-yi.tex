%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
%\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage{graphicx}
%\usepackage[margin=0.5in]{geometry} % this controls page margin
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
%\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\usepackage{sectsty} % Allows customizing section commands
%\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

%\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
\textsc{Stanford CS 229 Fall 2017} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\Large Final Project Milestone: \\
\Large Real Time Tennis Match Prediction Using Machine Learning\\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Yang "Eddie" Chen, Yi Zhong, Yubo Tian} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%	Section 1 Motivation
%----------------------------------------------------------------------------------------

\section{Motivation}
In the 2017 Stuttgart Open, Roger Federer, then an 18-time grand slam champion, lost to the world No. 302 player Tommy Haas on a grass court, which hadn't happened since 2002.  Based on past performance alone, any model would have predicted a Federer win in pre-game bets. This motivates us to apply machine learning to predict tennis matches in real time; in particular, we want to apply a hybrid model that combines historical and real-time information, similar to the model used by ESPN in-game prediction for NFL games.

Tennis is an ideal candidate for using a hierarchical probability model as a match consists of a sequence of sets, which in turn consist of a sequence of games, which in turn consist of a sequence of points.  Recent researches also began to apply machine learning on tennis pre-game predictions based on past performance (including previous encounter, current ranking, etc). Utilizing existing data and building on top of existing research such as Sipko \cite{tennis1}, Clarke and Dyte \cite{Clarke2010} and Knottenbelt \cite{KNOTTENBELT20123820}, this paper seeks to apply classification algorithms from machine learning to model men's professional singles matches by using both pre-game, historical performance calcualted via a common opponent model \cite{KNOTTENBELT20123820}, and real-time, on-court stats \cite{tennis_charting} \cite{tennis2setbyset}. As pointed out by Sipko \cite{tennis1}, an in-game approach "allows the model to capture the change in a player's performance over the course of the match. For example, different players fatigue during a match in different ways." We hope that results from our predictions can be extended to give real-time coaching advice to support game strategy decision.
%----------------------------------------------------------------------------------------
%	Section 2 - Method
%----------------------------------------------------------------------------------------

\section{Method}
\subsection{Feature Extraction}
\label{sec:label}
Our dataset denotes Player 1 as the winner and Player 2 as the loser.  Hence we represent each set in each match with two rows, one from each player's perspective.  There is one row per set per match, contains features from historical and real-time aspect.  For the scope of this project, real-time aspect will be defined as the performance in previous set:
\begin{enumerate}
\item A vector of input features (X), describing the performance in previous set and historical performance of both players
\item A target value (y), indicating the match outcome
\end{enumerate}
\subsubsection{Symmetric Feature Representation}
There are two approaches to represent features from two players.  First, we can have two features for the same metric.  This approach doubles the number of features, but also provides a quantitative measure that we can compare across all players.  Second, we can represent difference between two players ($RANK_DIFF = RANK_1 - RANK_2$, as opposed to $RANK_1$ and $RANK_2$).  This would reduce the number of features, but does not allow the model to compare across players.  Previous research has shown that the difference variables are predictive enough \cite{tennis1} \cite{omalley} for past performance (match level).  For current performance (set level), we will evaluate the performance of both approaches.  
\textbf{TODO}
\subsubsection{Common Opponent Model for Past Performance}
We use a method proposed by Knottenbelt \cite{KNOTTENBELT20123820} and extended by Spiko \cite{tennis1} to construct difference variables capturing player characteristics and past performance, by using their \textbf{common opponents} to achieve a fair comparison. 
This method first looks for a set of \textbf{common opponents} between the two players of a given match. Here, \textbf{common opponents} are defined as other players that the both have faced in the past on their own. Then we find both players' performance against the common opponent ($C_i$), and average across all the common opponents. Lastly, we find the difference between the two players' average stats against common opponents as the selected feature.  See B. Appendix for a detail overview of this method.
The limitation of this method is apparent: it only works well when players actually have common opponents have played games with them before the queried match date. Hence, we need to think about how to handle edge cases.
\subsubsection{Edge Cases}
We have run into 2 edge cases: (1) when at least one of the players is new; (2) when two players do not have any common opponents.  In our initial investigation, our solution is: (1) when the player is new with no historical data, we remove sample, which is X samples out of X 1421 matches; (2) when two players do not have any common opponents, we compute the average for each player (regardless of opponent) and take the difference.
\subsection{Data Preparation}
\subsubsection{Data Source}
We obtain match-level data from Jeff Sackmann's Github repositories \cite{tennis_atp} \cite{tennis_charting}, with the Match Charting Project (MCP) providing set-level stats and results as well \cite{tennis_charting}. Prediction is made based on MCP (1415 matches), where past performance for each MCP match is computed from tennis_atp (52758 matches).  Since our dataset comes from two sources, most of our milestone effort was spent on data cleaning and transformation, including detecting and removing duplicates, merge datasets based on limited information and omission of certain tournaments.  See Appendix D for more details on data cleaning.
\subsection{Feature List}
We present the list of extracted features in Table \ref{tab:features}. Note that all these features are difference variables unless otherwise noted. 
\begin{center}
\begin{table}[h]
    \begin{tabular}{  l | p{10cm} }
    \hline
    Feature  & Description \\ \hline
    \textbf{DURATION}  & Match duration in minutes (\textit{not difference}) \\ \hline
    \textbf{SAME\_HANDEDNESS}  & Tracking, on average, the frequency of facing opponents who have the same dominant hand \\ \hline
    \textbf{RANK}  & ATP rank \\ \hline
    \textbf{RANK\_PTS}  & ATP rank points \\ \hline
    \textbf{HEIGHT}  & Player height \\ \hline
    \textbf{FSP}  & First serve success percentage \\ \hline
    \textbf{ACE}  & Average number of aces per game \\ \hline
    \textbf{DF}  & Average number of double faults per game \\ \hline
    \textbf{BP\_FACED}  & Average number of break points faced per game \\ \hline
    \textbf{BP\_SAVED}  & Average number of break points saved per game \\ \hline
    \textbf{BPP}  & Break point saving percentage \\ \hline
    \textbf{SVGM}  & Average number of serve games \\ \hline
    \textbf{W1SP}  & Winning on first serve percentage \\ \hline
    \textbf{W2SP}  & Winning on second serve percentage \\ \hline
    \textbf{SVPT}  & Average number of serve points per game \\ \hline
    \end{tabular}
    \caption{Summary of extracted features}
    \label{tab:features}
    \end{table}
\end{center}
%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
%	Section Preliminary Experiments
%----------------------------------------------------------------------------------------

\section{Preliminary Experiments}
As the team is still working on connecting the historical, match-level dataset with the real-time, set-level data sets, we ran some preliminary models fitting the two datasets separately instead. We use scikit-learn's implementation of the various models \cite{scikit-learn}.
\subsection{Historical, Match-level Dataset: Logistic Regression Model}
Applying a train-test split of 2:1, we trained a logistic regression model on 2/3 of all the ATP matches from 2012. Following the labelling from Section~\ref{sec:label}, we set $label = 1$ for all the matches with Player 1 being the Winner (notation-only), and then duplicated the entire dataset but swapped Player 1 and Player 2 and set $label = 0$, as well as inverted all difference features. \textbf{TODO}: might need more explanation? 

We achieved an impressive accuracy rate of 87.8\% just using the historical, match-level dataset with common opponent model and difference variables. 
\subsubsection{Error Analysis}
A preliminary error analysis was done to explore the relative importance of all the extracted features, and the results are shown in Table~\ref{tab:logreg}. Interestingly, we note that \textbf{RANK\_PTS} accounts for almost $20\%$ of the performance. 
\begin{center}
\begin{table}[h]
    \begin{tabular}{  l | l | l | p{5cm} }
    \hline
Order &     Accuracy Rate    &         Feature    &  Performance Difference \\ \hline
0    &    0.878170 &              \textbf{SVPT}  &      \\ \hline
1    &    0.878170 &        \textbf{SAME\_HANDEDNESS}  & 0.00\% \\ \hline
2    &    0.666483 &          \textbf{RANK\_PTS} & -21.17\% \\ \hline
3    &    0.657111 &              \textbf{RANK} & -0.94\% \\ \hline
4    &    0.660419 &            \textbf{HEIGHT} & 0.33\% \\ \hline
5    &    0.659868 &  \textbf{FSP} & -0.06\% \\ \hline
6    &    0.665932 &       \textbf{DURATION} &  0.61\% \\ \hline
7    &    0.661521 &                \textbf{DF} & -0.44\% \\ \hline
8    &    0.664278 &    \textbf{BPP} &  0.28\% \\ \hline
9    &    0.664829 &         \textbf{BP\_SAVED} &  0.06\% \\ \hline
10   &    0.665380 &          \textbf{BP\_FACED}  & 0.06\% \\ \hline
11   &    0.648842 &    \textbf{ACE} & -1.65\% \\ \hline
12   &    0.661521 &             \textbf{SVGM} & 1.27\% \\ \hline
13   &    0.659868 & \textbf{W2SP} & -0.17\% \\ \hline
    \end{tabular}
    \caption{Summary of extracted feature performance in the preliminary logistic regression model fitting on historical match-level data}
    \label{tab:logreg}
    \end{table}
\end{center}
\subsection{Historical, Match-level Dataset: Naive Bayes Classifier}
We also ran the data through a Gaussian-based Naive Bayes classifier, which showed an impressive 86.9\% accuracy rate (misclassifying 718 points out of 5496). As expected, it was also extremely fast. The impressive performance indicates that the extracted features might indeed be conditionally independent of each other, which is something we never thought of before, and look to explore in the next steps. On a first glance, it seems to suggest that given Player $i$ won the match, his/her performance on aces and rank point difference or double faults are indeed almost independent. We were surprised by the results, and more sanity check is needed before we put ourselves behind this. 
\subsection{Real-time, Set-level Dataset: Logistic Regression Model}
\textbf{TODO}
\subsection{Real-time, Set-level Dataset:  SVM}
\textbf{TODO}

%----------------------------------------------------------------------------------------
%	Section Next Steps
%----------------------------------------------------------------------------------------

\section{Next Steps}
The biggest next step is to connect the historical, match-level dataset with the real-time, set-level data set in order to conduct further experiments. We also plan to incorporate more sophisticated ideas on feature scaling in the context of tennis, such as \textbf{time discounting}, \textbf{surface weighting}, and the effect of fatigue and player injury. Moreover, we wanted to explore more interesting features such as \textbf{head-to-head results}, as well as to conduct \textbf{Principal Component Analysis} and \textbf{Feature Selection} to understand the inter-correlation between features, and which features are more predictive than others. Lastly, we plan to benchmark various machine learning models' performances, and to fine-tune the best them to achieve optimal performance. 
%----------------------------------------------------------------------------------------
%	Conclusion
%----------------------------------------------------------------------------------------
\section{Conclusion}
The use of common opponent model and difference variables already offer high predictive power in simple machine learning models such as logistic regression and Naive Bayes, and it's exciting to see with fine-tuning and more exploration and connecting datasets what we can achieve. It's also helpful to learn that ATP rank point difference between two players alone is already predictive of their likely match outcome. 

\appendix
%----------------------------------------------------------------------------------------
%	Section Contributions
%----------------------------------------------------------------------------------------

\section{Contributions}
\subsection{Yi Zhong}
\begin{itemize}
\item Data processing: get match details related features from MatchChartingProject, link MatchChartingProject to ATPMatches (methods: playerID, playerName etc), link match details data to current match data
\item Initial modeling: Logistic regression + SVM with current match data (after set 1 and after set 2)
\item Error analyses in the logistic regression and SVM models
\end{itemize}


\subsection{Yubo Tian}
\subsection{Yang "Eddie" Chen}
\begin{itemize}
\item Researched and reviewed relevant literature for applicable ideas, such as Clarke and Dyte \cite{Clarke2010} and O'Malley \cite{omalley} for difference variable, and Knottenbelt \cite{KNOTTENBELT20123820} for the common opponent model
\item Implemented the Common Opponent Model to look up players stats from common opponents
\item Generated ATP Match results for labels
\item Typsetted (\LaTeX) the project milestone report
\end{itemize}

\section{Appendix: Project Roadmap}
\begin{itemize}
\item \textbf{11/13 - 11/19}: Data cleaning
\item \textbf{11/20 - 11/26}: Preliminary experiements, building out more sophisticated ideas into models such as surface weighting, time decaying, fatigue, and injury
\item \textbf{11/27 - 12/03}: Continue fine-tuning models
\item \textbf{12/04 - 12/10}: Poster making
\item \textbf{12/11 - 12/15}: Poster presentation; final project write-up
\end{itemize}

\section{Appendix: Common Opponent Model for Past Performance}
Figure \ref{fig:CO} shows an example of how we could construct the \textbf{ACE} feature (difference in average ace counts) against common opponents. 
\begin{figure}
  \caption{Constructing the ACE feature using common opponents}
  \centering
    \includegraphics[width=0.8\textwidth]{CO}
  \label{fig:CO}
\end{figure}
As shown in Figure \ref{fig:CO}, common opponents are labeled as $C_1, C_2, ...C_n$. For Player $i \in \{1,2\}$, $ACE_i(C_j)$ is his/her average count of aces in all matches against common opponent $C_j$. We then take an average of these values to get $ACE_i$ for Player $i$: $$ACE_i = \frac{\Sigma_{j=0}^n ACE_i(C_j)}{n}$$
Lastly, applying the idea of difference variables, we create the feature ACE by finding the difference in performance on this feature between Player 1 and Player 2: $$ACE = ACE_1 - ACE_2$$.  We implemented this model on all features for past performance.

\section{Appendix: Data Cleaning \& Transformation}
\textbf{TODO}: Things to talk about:
\begin{itemize}
\item Validations run on the datasets
\item How to detect and remove duplicates
\item Decision on dropping Davis Cup data (because team tourney might have different strategies, hence introducing biases)
\item How to merge two datasets together
\item (TODO for future work) Standardize features? 
\end{itemize}


\bibliographystyle{plain}
\bibliography{ref} 

\end{document}